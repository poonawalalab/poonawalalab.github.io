---
class: "conference"
authors: "Muthirayan, D.;Khargonekar, P."
title: "Working Memory Augmentation for Improved Learning in Neural Adaptive Control"
venue: "IEEE Conference on Decision and Control"
year: "2019"
layout: page
---

## Overview
This paper revisits neural-network based adaptive control (Frank Lewis at UT Arlington did a lot of this) by adding a form of memory to the adaptation. Traditional adaptive control is typically driven by the current error, without any storage of information.
This paper is interesting because the memory appears to be like the attention mechanism in Transformers.
The authors show that using the error improves the performance, but this performance is purely a visual interpretation of a graph with 'faster convergence'.

## Basic models
They consider a sustem of the form
\(\begin{aligned}
\dot x &= A x + B  (u + f(x)) + B_r r,
\end{aligned}\)
where
* $x$ is the state
* $f(x)$ is an unknown nonlinear term
* $r$ is a command signal
* The reference $x_{ref}(t)$ is generated by another dynamical system $\dot x_{ref} = A_{ref} x_{ref} + B_r r$
The goal is to have $x(t)$ track the reference $x_{ref}(t)$.

### Adaptive Control
As they mention, the control $u$ will have a term generated by an NN $\hat f(x)$ that will essentially cancel out $f(x)$ by learning adaptively.
So, the control is of the form $$ u = u_{bl} + u_{ad} + v,$$
where $u_{ad} = - \hat f(x)$, the NN estimate of $f(x)$. The baseline controller $u_{bl}$ is pre-designed, and $v$ is a 'robustifying' term

Here, I modify the symbols from the paper to match work that I've done before.
They assume that $f(x)$ corresponds to some (unknown) network
$$f(x) = W \sigma(H x + b) + c,$$
so that our estimator is
$$\hat f(x) = \hat W \sigma(\hat H x + \hat b) + \hat c.$$

The update for these 'hat' parameters are taken from [Multilayer Neural Net Robot Controller With Guaranteed Tracking Performance, by F. Lewis and others, 1996.], and corresponds to an control-theoretic modification of backpropagation rules (Equations (41) and (42)).  

### Memory
A set of $n_s$ vectors $\mu_i \in \R^N$ forms the memory representation. This memory is therefore also a $n_s \times N$ matrix $\mu$.

* Reading from memory is like an attention mechanism, where the keys are the values:
  * Let  $z =  \mathrm{softmax}(\mu^T q)$ (combines query with memory to define a weighting for memory entries)
  * $M_r  = \mu z $
  * In practice, they choose $q = \text{hidden layer}=\sigma(\hat H x + \hat b)$
* Writing to memory combines forgetting with a term that appears to memorize activation patterns, given $a$ and $z$ definitions.
  * $\dot \mu_ {i} = -z_i \mu_i + c_w z_i a + z_i \hat W q_{\mu}^T$ (4), where
    * $a = \text{hidden layer} = \sigma(\hat H x + \hat b)$
    * For the third term, as the authors write:
      >The third term in equation (4) is the regular parameter update that arises from the memory vectors Î¼is being perceived as additional parameters of the NN by the NN learning algorithm. Here $q_\mu$ depends on the problem and $c_w$ is a design constant.  

  * After Equation (10), they mention that
     >The variable $q_{\mu}$ in (4) is problem specific and depends on
the Lyapunov function (without the NN error term).

  * Going through Frank Lewis' paper, we see that $q_{\mu}$ appears to be what they call a filtered tracking error $r$ that appears to be the term $r = \dot e + \Lambda e$ using in passivity-based adaptive control

### Adaptive Control With Memory
The paper is a bit strange to read because the adaptive control and memory update rules are actually inter-dependent, but they try to separate it out as if the adaptive control and the memory terms are independent concepts.  

The neural network $\hat f(x)$ is modified by the memory readout when generating the control $u_{ad} = -\hat f(x)$:
$$ \hat f(x) = \hat W \left( \sigma(\hat H x + \hat b )+ M_r\right) + \hat c$$

The authors are vague about saying that $q_{\mu}$ comes from a Lyapunov function for the tracking error, and is likely related to the filtered tracking reference mentioned above.
